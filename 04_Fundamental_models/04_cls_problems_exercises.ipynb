{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Machine Learning in Geosciences ] \n",
    "Department of Applied Geoinformatics and Carthography, Charles University\n",
    "\n",
    "Lukas Brodsky lukas.brodsky@natur.cuni.cz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: apply different ML algorithms to different classification problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: explore selected classification algoritms based on simulated synthetic data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports for reading, visualizing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data preparattion \n",
    "from sklearn.datasets import make_classification # make_blobs\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiers: \n",
    "\n",
    "# LINEAR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# TREES\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# SVM \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "# ANN \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Accuracy assesment \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# tuning -> manual, so far \n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the simulated data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data set 1\n",
    "X1, y1 = make_classification(n_samples = 1000, n_features = 10, n_informative = 5, n_redundant = 5, \n",
    "                          class_sep = 3, n_clusters_per_class=1, \n",
    "                          random_state = 42, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X1[(y1==0),0], X1[(y1==0),1], 'r.')\n",
    "plt.plot(X1[(y1==1),0], X1[(y1==1),1], 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array to pandas dataframe\n",
    "# features = [f\"Feature {ii+1}\" for ii in range(X1.shape[1])]\n",
    "# X1 = pd.DataFrame(X1, columns = features)\n",
    "# y1 = pd.DataFrame(y1, columns = [\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = make_moons(n_samples=1000,  noise=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X2[(y2==0),0], X2[(y2==0),1], 'r.')\n",
    "plt.plot(X2[(y2==1),0], X2[(y2==1),1], 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array to pandas dataframe\n",
    "# features = [f\"Feature {ii+1}\" for ii in range(X3.shape[1])]\n",
    "# X2 = pd.DataFrame(X2, columns = features)\n",
    "# y2 = pd.DataFrame(y2, columns = [\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 20 % \n",
    "# train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select clasifiers & instantiate, set hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate classifiers \n",
    "\n",
    "# 1. Linear SVM (suppor vector classifier) \n",
    "# PARAMS: C = 0.01, 0.1, 1.0, 10, 100\n",
    "# lsvc_cls = pass\n",
    "\n",
    "# 2. Non-linear SVM (suppor vector classifier) \n",
    "# PARAMS: kernel = \"linear\", \"rbf\", \"poly\"\n",
    "#         gamma = \"auto\"\n",
    "#         C = 0.1, 0.5, 1, 5, 10, 50, 100 \n",
    "model = SVC(kernel=\"rbf\", gamma=\"auto\", C = 0.1) \n",
    "\n",
    "\n",
    "# 3. MLP ANN - MLPClassifier() \n",
    "# PARAMS: hidden_layer_sizes = 3, 10, 20\n",
    "#         learning_rate = 'constant'\n",
    "#         learning_rate_init 0.001, 0.01, 0.1\n",
    "#         max_iter = 100\n",
    "# mlp_clf = pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT model.fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training - cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model \n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature1, 2 from X \n",
    "feature_1, feature_2 = np.meshgrid(\n",
    "     np.linspace(X_train[:, 0].min(), X_train[:, 0].max()),\n",
    "     np.linspace(X_train[:, 1].min(), X_train[:, 1].max())\n",
    ")\n",
    "grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.reshape(model.predict(grid), feature_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display data with boundary\n",
    "\n",
    "display = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_pred)\n",
    "display.plot(alpha=0.5)\n",
    "display.ax_.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolor=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/ Which model works well for the data set 1 and 2? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework: \n",
    "# 2/ Change class_sep = 1 for data set 1 and evaluate models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework: \n",
    "# 3/ Change noise=0.3 for data set 2 and evaluate models performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
